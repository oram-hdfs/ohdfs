// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_server_common_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnServerCommonProtos {
  private YarnServerCommonProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code hadoop.yarn.NodeActionProto}
   */
  public enum NodeActionProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NORMAL = 0;</code>
     */
    NORMAL(0, 0),
    /**
     * <code>RESYNC = 1;</code>
     */
    RESYNC(1, 1),
    /**
     * <code>SHUTDOWN = 2;</code>
     */
    SHUTDOWN(2, 2),
    ;

    /**
     * <code>NORMAL = 0;</code>
     */
    public static final int NORMAL_VALUE = 0;
    /**
     * <code>RESYNC = 1;</code>
     */
    public static final int RESYNC_VALUE = 1;
    /**
     * <code>SHUTDOWN = 2;</code>
     */
    public static final int SHUTDOWN_VALUE = 2;


    public final int getNumber() { return value; }

    public static NodeActionProto valueOf(int value) {
      switch (value) {
        case 0: return NORMAL;
        case 1: return RESYNC;
        case 2: return SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NodeActionProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<NodeActionProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NodeActionProto>() {
            public NodeActionProto findValueByNumber(int number) {
              return NodeActionProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final NodeActionProto[] VALUES = values();

    public static NodeActionProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private NodeActionProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.NodeActionProto)
  }

  public interface NodeStatusProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional int32 response_id = 2;
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    boolean hasResponseId();
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    int getResponseId();

    // repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> 
        getContainersStatusesList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getContainersStatuses(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    int getContainersStatusesCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getContainersStatusesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getContainersStatusesOrBuilder(
        int index);

    // optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    boolean hasNodeHealthStatus();
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto getNodeHealthStatus();
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder getNodeHealthStatusOrBuilder();

    // repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> 
        getKeepAliveApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getKeepAliveApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    int getKeepAliveApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getKeepAliveApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getKeepAliveApplicationsOrBuilder(
        int index);

    // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    boolean hasContainersUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder();

    // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    boolean hasNodeUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder();

    // repeated .hadoop.yarn.ContainerProto increased_containers = 8;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getIncreasedContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    int getIncreasedContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getIncreasedContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeStatusProto}
   */
  public static final class NodeStatusProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeStatusProtoOrBuilder {
    // Use NodeStatusProto.newBuilder() to construct.
    private NodeStatusProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeStatusProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeStatusProto defaultInstance;
    public static NodeStatusProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeStatusProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              responseId_ = input.readInt32();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                containersStatuses_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              containersStatuses_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = nodeHealthStatus_.toBuilder();
              }
              nodeHealthStatus_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeHealthStatus_);
                nodeHealthStatus_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                keepAliveApplications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>();
                mutable_bitField0_ |= 0x00000010;
              }
              keepAliveApplications_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = containersUtilization_.toBuilder();
              }
              containersUtilization_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containersUtilization_);
                containersUtilization_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 58: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = nodeUtilization_.toBuilder();
              }
              nodeUtilization_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeUtilization_);
                nodeUtilization_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 66: {
              if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
                increasedContainers_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000080;
              }
              increasedContainers_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          containersStatuses_ = java.util.Collections.unmodifiableList(containersStatuses_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          keepAliveApplications_ = java.util.Collections.unmodifiableList(keepAliveApplications_);
        }
        if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
          increasedContainers_ = java.util.Collections.unmodifiableList(increasedContainers_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeStatusProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeStatusProto>() {
      public NodeStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeStatusProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeStatusProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional int32 response_id = 2;
    public static final int RESPONSE_ID_FIELD_NUMBER = 2;
    private int responseId_;
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    public boolean hasResponseId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 response_id = 2;</code>
     */
    public int getResponseId() {
      return responseId_;
    }

    // repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;
    public static final int CONTAINERSSTATUSES_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> containersStatuses_;
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getContainersStatusesList() {
      return containersStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
        getContainersStatusesOrBuilderList() {
      return containersStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    public int getContainersStatusesCount() {
      return containersStatuses_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getContainersStatuses(int index) {
      return containersStatuses_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getContainersStatusesOrBuilder(
        int index) {
      return containersStatuses_.get(index);
    }

    // optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;
    public static final int NODEHEALTHSTATUS_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto nodeHealthStatus_;
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    public boolean hasNodeHealthStatus() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto getNodeHealthStatus() {
      return nodeHealthStatus_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder getNodeHealthStatusOrBuilder() {
      return nodeHealthStatus_;
    }

    // repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;
    public static final int KEEP_ALIVE_APPLICATIONS_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> keepAliveApplications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getKeepAliveApplicationsList() {
      return keepAliveApplications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getKeepAliveApplicationsOrBuilderList() {
      return keepAliveApplications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    public int getKeepAliveApplicationsCount() {
      return keepAliveApplications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getKeepAliveApplications(int index) {
      return keepAliveApplications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getKeepAliveApplicationsOrBuilder(
        int index) {
      return keepAliveApplications_.get(index);
    }

    // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;
    public static final int CONTAINERS_UTILIZATION_FIELD_NUMBER = 6;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto containersUtilization_;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    public boolean hasContainersUtilization() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization() {
      return containersUtilization_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder() {
      return containersUtilization_;
    }

    // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;
    public static final int NODE_UTILIZATION_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto nodeUtilization_;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    public boolean hasNodeUtilization() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization() {
      return nodeUtilization_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder() {
      return nodeUtilization_;
    }

    // repeated .hadoop.yarn.ContainerProto increased_containers = 8;
    public static final int INCREASED_CONTAINERS_FIELD_NUMBER = 8;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> increasedContainers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getIncreasedContainersList() {
      return increasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getIncreasedContainersOrBuilderList() {
      return increasedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    public int getIncreasedContainersCount() {
      return increasedContainers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index) {
      return increasedContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
        int index) {
      return increasedContainers_.get(index);
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      responseId_ = 0;
      containersStatuses_ = java.util.Collections.emptyList();
      nodeHealthStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance();
      keepAliveApplications_ = java.util.Collections.emptyList();
      containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      increasedContainers_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getIncreasedContainersCount(); i++) {
        if (!getIncreasedContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, responseId_);
      }
      for (int i = 0; i < containersStatuses_.size(); i++) {
        output.writeMessage(3, containersStatuses_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(4, nodeHealthStatus_);
      }
      for (int i = 0; i < keepAliveApplications_.size(); i++) {
        output.writeMessage(5, keepAliveApplications_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(6, containersUtilization_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(7, nodeUtilization_);
      }
      for (int i = 0; i < increasedContainers_.size(); i++) {
        output.writeMessage(8, increasedContainers_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, responseId_);
      }
      for (int i = 0; i < containersStatuses_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, containersStatuses_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, nodeHealthStatus_);
      }
      for (int i = 0; i < keepAliveApplications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, keepAliveApplications_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, containersUtilization_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, nodeUtilization_);
      }
      for (int i = 0; i < increasedContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, increasedContainers_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasResponseId() == other.hasResponseId());
      if (hasResponseId()) {
        result = result && (getResponseId()
            == other.getResponseId());
      }
      result = result && getContainersStatusesList()
          .equals(other.getContainersStatusesList());
      result = result && (hasNodeHealthStatus() == other.hasNodeHealthStatus());
      if (hasNodeHealthStatus()) {
        result = result && getNodeHealthStatus()
            .equals(other.getNodeHealthStatus());
      }
      result = result && getKeepAliveApplicationsList()
          .equals(other.getKeepAliveApplicationsList());
      result = result && (hasContainersUtilization() == other.hasContainersUtilization());
      if (hasContainersUtilization()) {
        result = result && getContainersUtilization()
            .equals(other.getContainersUtilization());
      }
      result = result && (hasNodeUtilization() == other.hasNodeUtilization());
      if (hasNodeUtilization()) {
        result = result && getNodeUtilization()
            .equals(other.getNodeUtilization());
      }
      result = result && getIncreasedContainersList()
          .equals(other.getIncreasedContainersList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasResponseId()) {
        hash = (37 * hash) + RESPONSE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getResponseId();
      }
      if (getContainersStatusesCount() > 0) {
        hash = (37 * hash) + CONTAINERSSTATUSES_FIELD_NUMBER;
        hash = (53 * hash) + getContainersStatusesList().hashCode();
      }
      if (hasNodeHealthStatus()) {
        hash = (37 * hash) + NODEHEALTHSTATUS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeHealthStatus().hashCode();
      }
      if (getKeepAliveApplicationsCount() > 0) {
        hash = (37 * hash) + KEEP_ALIVE_APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getKeepAliveApplicationsList().hashCode();
      }
      if (hasContainersUtilization()) {
        hash = (37 * hash) + CONTAINERS_UTILIZATION_FIELD_NUMBER;
        hash = (53 * hash) + getContainersUtilization().hashCode();
      }
      if (hasNodeUtilization()) {
        hash = (37 * hash) + NODE_UTILIZATION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeUtilization().hashCode();
      }
      if (getIncreasedContainersCount() > 0) {
        hash = (37 * hash) + INCREASED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getIncreasedContainersList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getContainersStatusesFieldBuilder();
          getNodeHealthStatusFieldBuilder();
          getKeepAliveApplicationsFieldBuilder();
          getContainersUtilizationFieldBuilder();
          getNodeUtilizationFieldBuilder();
          getIncreasedContainersFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        responseId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (containersStatusesBuilder_ == null) {
          containersStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          containersStatusesBuilder_.clear();
        }
        if (nodeHealthStatusBuilder_ == null) {
          nodeHealthStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance();
        } else {
          nodeHealthStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (keepAliveApplicationsBuilder_ == null) {
          keepAliveApplications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          keepAliveApplicationsBuilder_.clear();
        }
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
        } else {
          containersUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
        } else {
          nodeUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        if (increasedContainersBuilder_ == null) {
          increasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
        } else {
          increasedContainersBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.responseId_ = responseId_;
        if (containersStatusesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            containersStatuses_ = java.util.Collections.unmodifiableList(containersStatuses_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.containersStatuses_ = containersStatuses_;
        } else {
          result.containersStatuses_ = containersStatusesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        if (nodeHealthStatusBuilder_ == null) {
          result.nodeHealthStatus_ = nodeHealthStatus_;
        } else {
          result.nodeHealthStatus_ = nodeHealthStatusBuilder_.build();
        }
        if (keepAliveApplicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            keepAliveApplications_ = java.util.Collections.unmodifiableList(keepAliveApplications_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.keepAliveApplications_ = keepAliveApplications_;
        } else {
          result.keepAliveApplications_ = keepAliveApplicationsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        if (containersUtilizationBuilder_ == null) {
          result.containersUtilization_ = containersUtilization_;
        } else {
          result.containersUtilization_ = containersUtilizationBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        if (nodeUtilizationBuilder_ == null) {
          result.nodeUtilization_ = nodeUtilization_;
        } else {
          result.nodeUtilization_ = nodeUtilizationBuilder_.build();
        }
        if (increasedContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080)) {
            increasedContainers_ = java.util.Collections.unmodifiableList(increasedContainers_);
            bitField0_ = (bitField0_ & ~0x00000080);
          }
          result.increasedContainers_ = increasedContainers_;
        } else {
          result.increasedContainers_ = increasedContainersBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasResponseId()) {
          setResponseId(other.getResponseId());
        }
        if (containersStatusesBuilder_ == null) {
          if (!other.containersStatuses_.isEmpty()) {
            if (containersStatuses_.isEmpty()) {
              containersStatuses_ = other.containersStatuses_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureContainersStatusesIsMutable();
              containersStatuses_.addAll(other.containersStatuses_);
            }
            onChanged();
          }
        } else {
          if (!other.containersStatuses_.isEmpty()) {
            if (containersStatusesBuilder_.isEmpty()) {
              containersStatusesBuilder_.dispose();
              containersStatusesBuilder_ = null;
              containersStatuses_ = other.containersStatuses_;
              bitField0_ = (bitField0_ & ~0x00000004);
              containersStatusesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainersStatusesFieldBuilder() : null;
            } else {
              containersStatusesBuilder_.addAllMessages(other.containersStatuses_);
            }
          }
        }
        if (other.hasNodeHealthStatus()) {
          mergeNodeHealthStatus(other.getNodeHealthStatus());
        }
        if (keepAliveApplicationsBuilder_ == null) {
          if (!other.keepAliveApplications_.isEmpty()) {
            if (keepAliveApplications_.isEmpty()) {
              keepAliveApplications_ = other.keepAliveApplications_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureKeepAliveApplicationsIsMutable();
              keepAliveApplications_.addAll(other.keepAliveApplications_);
            }
            onChanged();
          }
        } else {
          if (!other.keepAliveApplications_.isEmpty()) {
            if (keepAliveApplicationsBuilder_.isEmpty()) {
              keepAliveApplicationsBuilder_.dispose();
              keepAliveApplicationsBuilder_ = null;
              keepAliveApplications_ = other.keepAliveApplications_;
              bitField0_ = (bitField0_ & ~0x00000010);
              keepAliveApplicationsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getKeepAliveApplicationsFieldBuilder() : null;
            } else {
              keepAliveApplicationsBuilder_.addAllMessages(other.keepAliveApplications_);
            }
          }
        }
        if (other.hasContainersUtilization()) {
          mergeContainersUtilization(other.getContainersUtilization());
        }
        if (other.hasNodeUtilization()) {
          mergeNodeUtilization(other.getNodeUtilization());
        }
        if (increasedContainersBuilder_ == null) {
          if (!other.increasedContainers_.isEmpty()) {
            if (increasedContainers_.isEmpty()) {
              increasedContainers_ = other.increasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000080);
            } else {
              ensureIncreasedContainersIsMutable();
              increasedContainers_.addAll(other.increasedContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.increasedContainers_.isEmpty()) {
            if (increasedContainersBuilder_.isEmpty()) {
              increasedContainersBuilder_.dispose();
              increasedContainersBuilder_ = null;
              increasedContainers_ = other.increasedContainers_;
              bitField0_ = (bitField0_ & ~0x00000080);
              increasedContainersBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getIncreasedContainersFieldBuilder() : null;
            } else {
              increasedContainersBuilder_.addAllMessages(other.increasedContainers_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getIncreasedContainersCount(); i++) {
          if (!getIncreasedContainers(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto node_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional int32 response_id = 2;
      private int responseId_ ;
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public boolean hasResponseId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public int getResponseId() {
        return responseId_;
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public Builder setResponseId(int value) {
        bitField0_ |= 0x00000002;
        responseId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 response_id = 2;</code>
       */
      public Builder clearResponseId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        responseId_ = 0;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> containersStatuses_ =
        java.util.Collections.emptyList();
      private void ensureContainersStatusesIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          containersStatuses_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto>(containersStatuses_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> containersStatusesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> getContainersStatusesList() {
        if (containersStatusesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersStatuses_);
        } else {
          return containersStatusesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public int getContainersStatusesCount() {
        if (containersStatusesBuilder_ == null) {
          return containersStatuses_.size();
        } else {
          return containersStatusesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getContainersStatuses(int index) {
        if (containersStatusesBuilder_ == null) {
          return containersStatuses_.get(index);
        } else {
          return containersStatusesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder setContainersStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (containersStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersStatusesIsMutable();
          containersStatuses_.set(index, value);
          onChanged();
        } else {
          containersStatusesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder setContainersStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (containersStatusesBuilder_ == null) {
          ensureContainersStatusesIsMutable();
          containersStatuses_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersStatusesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder addContainersStatuses(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (containersStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersStatusesIsMutable();
          containersStatuses_.add(value);
          onChanged();
        } else {
          containersStatusesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder addContainersStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (containersStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersStatusesIsMutable();
          containersStatuses_.add(index, value);
          onChanged();
        } else {
          containersStatusesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder addContainersStatuses(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (containersStatusesBuilder_ == null) {
          ensureContainersStatusesIsMutable();
          containersStatuses_.add(builderForValue.build());
          onChanged();
        } else {
          containersStatusesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder addContainersStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (containersStatusesBuilder_ == null) {
          ensureContainersStatusesIsMutable();
          containersStatuses_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersStatusesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder addAllContainersStatuses(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto> values) {
        if (containersStatusesBuilder_ == null) {
          ensureContainersStatusesIsMutable();
          super.addAll(values, containersStatuses_);
          onChanged();
        } else {
          containersStatusesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder clearContainersStatuses() {
        if (containersStatusesBuilder_ == null) {
          containersStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          containersStatusesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public Builder removeContainersStatuses(int index) {
        if (containersStatusesBuilder_ == null) {
          ensureContainersStatusesIsMutable();
          containersStatuses_.remove(index);
          onChanged();
        } else {
          containersStatusesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder getContainersStatusesBuilder(
          int index) {
        return getContainersStatusesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getContainersStatusesOrBuilder(
          int index) {
        if (containersStatusesBuilder_ == null) {
          return containersStatuses_.get(index);  } else {
          return containersStatusesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
           getContainersStatusesOrBuilderList() {
        if (containersStatusesBuilder_ != null) {
          return containersStatusesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersStatuses_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addContainersStatusesBuilder() {
        return getContainersStatusesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder addContainersStatusesBuilder(
          int index) {
        return getContainersStatusesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerStatusProto containersStatuses = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder> 
           getContainersStatusesBuilderList() {
        return getContainersStatusesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
          getContainersStatusesFieldBuilder() {
        if (containersStatusesBuilder_ == null) {
          containersStatusesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder>(
                  containersStatuses_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          containersStatuses_ = null;
        }
        return containersStatusesBuilder_;
      }

      // optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto nodeHealthStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder> nodeHealthStatusBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public boolean hasNodeHealthStatus() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto getNodeHealthStatus() {
        if (nodeHealthStatusBuilder_ == null) {
          return nodeHealthStatus_;
        } else {
          return nodeHealthStatusBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public Builder setNodeHealthStatus(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto value) {
        if (nodeHealthStatusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeHealthStatus_ = value;
          onChanged();
        } else {
          nodeHealthStatusBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public Builder setNodeHealthStatus(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder builderForValue) {
        if (nodeHealthStatusBuilder_ == null) {
          nodeHealthStatus_ = builderForValue.build();
          onChanged();
        } else {
          nodeHealthStatusBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public Builder mergeNodeHealthStatus(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto value) {
        if (nodeHealthStatusBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              nodeHealthStatus_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance()) {
            nodeHealthStatus_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.newBuilder(nodeHealthStatus_).mergeFrom(value).buildPartial();
          } else {
            nodeHealthStatus_ = value;
          }
          onChanged();
        } else {
          nodeHealthStatusBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public Builder clearNodeHealthStatus() {
        if (nodeHealthStatusBuilder_ == null) {
          nodeHealthStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance();
          onChanged();
        } else {
          nodeHealthStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder getNodeHealthStatusBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getNodeHealthStatusFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder getNodeHealthStatusOrBuilder() {
        if (nodeHealthStatusBuilder_ != null) {
          return nodeHealthStatusBuilder_.getMessageOrBuilder();
        } else {
          return nodeHealthStatus_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeHealthStatusProto nodeHealthStatus = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder> 
          getNodeHealthStatusFieldBuilder() {
        if (nodeHealthStatusBuilder_ == null) {
          nodeHealthStatusBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder>(
                  nodeHealthStatus_,
                  getParentForChildren(),
                  isClean());
          nodeHealthStatus_ = null;
        }
        return nodeHealthStatusBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> keepAliveApplications_ =
        java.util.Collections.emptyList();
      private void ensureKeepAliveApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          keepAliveApplications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>(keepAliveApplications_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> keepAliveApplicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getKeepAliveApplicationsList() {
        if (keepAliveApplicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(keepAliveApplications_);
        } else {
          return keepAliveApplicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public int getKeepAliveApplicationsCount() {
        if (keepAliveApplicationsBuilder_ == null) {
          return keepAliveApplications_.size();
        } else {
          return keepAliveApplicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getKeepAliveApplications(int index) {
        if (keepAliveApplicationsBuilder_ == null) {
          return keepAliveApplications_.get(index);
        } else {
          return keepAliveApplicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder setKeepAliveApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (keepAliveApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.set(index, value);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder setKeepAliveApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (keepAliveApplicationsBuilder_ == null) {
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.set(index, builderForValue.build());
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder addKeepAliveApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (keepAliveApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.add(value);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder addKeepAliveApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (keepAliveApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.add(index, value);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder addKeepAliveApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (keepAliveApplicationsBuilder_ == null) {
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.add(builderForValue.build());
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder addKeepAliveApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (keepAliveApplicationsBuilder_ == null) {
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.add(index, builderForValue.build());
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder addAllKeepAliveApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> values) {
        if (keepAliveApplicationsBuilder_ == null) {
          ensureKeepAliveApplicationsIsMutable();
          super.addAll(values, keepAliveApplications_);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder clearKeepAliveApplications() {
        if (keepAliveApplicationsBuilder_ == null) {
          keepAliveApplications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public Builder removeKeepAliveApplications(int index) {
        if (keepAliveApplicationsBuilder_ == null) {
          ensureKeepAliveApplicationsIsMutable();
          keepAliveApplications_.remove(index);
          onChanged();
        } else {
          keepAliveApplicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getKeepAliveApplicationsBuilder(
          int index) {
        return getKeepAliveApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getKeepAliveApplicationsOrBuilder(
          int index) {
        if (keepAliveApplicationsBuilder_ == null) {
          return keepAliveApplications_.get(index);  } else {
          return keepAliveApplicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
           getKeepAliveApplicationsOrBuilderList() {
        if (keepAliveApplicationsBuilder_ != null) {
          return keepAliveApplicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(keepAliveApplications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addKeepAliveApplicationsBuilder() {
        return getKeepAliveApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addKeepAliveApplicationsBuilder(
          int index) {
        return getKeepAliveApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto keep_alive_applications = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder> 
           getKeepAliveApplicationsBuilderList() {
        return getKeepAliveApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getKeepAliveApplicationsFieldBuilder() {
        if (keepAliveApplicationsBuilder_ == null) {
          keepAliveApplicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  keepAliveApplications_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          keepAliveApplications_ = null;
        }
        return keepAliveApplicationsBuilder_;
      }

      // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> containersUtilizationBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public boolean hasContainersUtilization() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization() {
        if (containersUtilizationBuilder_ == null) {
          return containersUtilization_;
        } else {
          return containersUtilizationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public Builder setContainersUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (containersUtilizationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containersUtilization_ = value;
          onChanged();
        } else {
          containersUtilizationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public Builder setContainersUtilization(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder builderForValue) {
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = builderForValue.build();
          onChanged();
        } else {
          containersUtilizationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public Builder mergeContainersUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (containersUtilizationBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              containersUtilization_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance()) {
            containersUtilization_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.newBuilder(containersUtilization_).mergeFrom(value).buildPartial();
          } else {
            containersUtilization_ = value;
          }
          onChanged();
        } else {
          containersUtilizationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public Builder clearContainersUtilization() {
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
          onChanged();
        } else {
          containersUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder getContainersUtilizationBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getContainersUtilizationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder() {
        if (containersUtilizationBuilder_ != null) {
          return containersUtilizationBuilder_.getMessageOrBuilder();
        } else {
          return containersUtilization_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> 
          getContainersUtilizationFieldBuilder() {
        if (containersUtilizationBuilder_ == null) {
          containersUtilizationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder>(
                  containersUtilization_,
                  getParentForChildren(),
                  isClean());
          containersUtilization_ = null;
        }
        return containersUtilizationBuilder_;
      }

      // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> nodeUtilizationBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public boolean hasNodeUtilization() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization() {
        if (nodeUtilizationBuilder_ == null) {
          return nodeUtilization_;
        } else {
          return nodeUtilizationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public Builder setNodeUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (nodeUtilizationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeUtilization_ = value;
          onChanged();
        } else {
          nodeUtilizationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public Builder setNodeUtilization(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder builderForValue) {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = builderForValue.build();
          onChanged();
        } else {
          nodeUtilizationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public Builder mergeNodeUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (nodeUtilizationBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              nodeUtilization_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance()) {
            nodeUtilization_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.newBuilder(nodeUtilization_).mergeFrom(value).buildPartial();
          } else {
            nodeUtilization_ = value;
          }
          onChanged();
        } else {
          nodeUtilizationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public Builder clearNodeUtilization() {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
          onChanged();
        } else {
          nodeUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder getNodeUtilizationBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getNodeUtilizationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder() {
        if (nodeUtilizationBuilder_ != null) {
          return nodeUtilizationBuilder_.getMessageOrBuilder();
        } else {
          return nodeUtilization_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> 
          getNodeUtilizationFieldBuilder() {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilizationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder>(
                  nodeUtilization_,
                  getParentForChildren(),
                  isClean());
          nodeUtilization_ = null;
        }
        return nodeUtilizationBuilder_;
      }

      // repeated .hadoop.yarn.ContainerProto increased_containers = 8;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> increasedContainers_ =
        java.util.Collections.emptyList();
      private void ensureIncreasedContainersIsMutable() {
        if (!((bitField0_ & 0x00000080) == 0x00000080)) {
          increasedContainers_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>(increasedContainers_);
          bitField0_ |= 0x00000080;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> increasedContainersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getIncreasedContainersList() {
        if (increasedContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(increasedContainers_);
        } else {
          return increasedContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public int getIncreasedContainersCount() {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.size();
        } else {
          return increasedContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getIncreasedContainers(int index) {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.get(index);
        } else {
          return increasedContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder setIncreasedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.set(index, value);
          onChanged();
        } else {
          increasedContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder setIncreasedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder addIncreasedContainers(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(value);
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder addIncreasedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (increasedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(index, value);
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder addIncreasedContainers(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder addIncreasedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          increasedContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder addAllIncreasedContainers(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          super.addAll(values, increasedContainers_);
          onChanged();
        } else {
          increasedContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder clearIncreasedContainers() {
        if (increasedContainersBuilder_ == null) {
          increasedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
          onChanged();
        } else {
          increasedContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public Builder removeIncreasedContainers(int index) {
        if (increasedContainersBuilder_ == null) {
          ensureIncreasedContainersIsMutable();
          increasedContainers_.remove(index);
          onChanged();
        } else {
          increasedContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getIncreasedContainersBuilder(
          int index) {
        return getIncreasedContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getIncreasedContainersOrBuilder(
          int index) {
        if (increasedContainersBuilder_ == null) {
          return increasedContainers_.get(index);  } else {
          return increasedContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getIncreasedContainersOrBuilderList() {
        if (increasedContainersBuilder_ != null) {
          return increasedContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(increasedContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addIncreasedContainersBuilder() {
        return getIncreasedContainersFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addIncreasedContainersBuilder(
          int index) {
        return getIncreasedContainersFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto increased_containers = 8;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getIncreasedContainersBuilderList() {
        return getIncreasedContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getIncreasedContainersFieldBuilder() {
        if (increasedContainersBuilder_ == null) {
          increasedContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  increasedContainers_,
                  ((bitField0_ & 0x00000080) == 0x00000080),
                  getParentForChildren(),
                  isClean());
          increasedContainers_ = null;
        }
        return increasedContainersBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeStatusProto)
    }

    static {
      defaultInstance = new NodeStatusProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeStatusProto)
  }

  public interface MasterKeyProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 key_id = 1;
    /**
     * <code>optional int32 key_id = 1;</code>
     */
    boolean hasKeyId();
    /**
     * <code>optional int32 key_id = 1;</code>
     */
    int getKeyId();

    // optional bytes bytes = 2;
    /**
     * <code>optional bytes bytes = 2;</code>
     */
    boolean hasBytes();
    /**
     * <code>optional bytes bytes = 2;</code>
     */
    com.google.protobuf.ByteString getBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.MasterKeyProto}
   */
  public static final class MasterKeyProto extends
      com.google.protobuf.GeneratedMessage
      implements MasterKeyProtoOrBuilder {
    // Use MasterKeyProto.newBuilder() to construct.
    private MasterKeyProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MasterKeyProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MasterKeyProto defaultInstance;
    public static MasterKeyProto getDefaultInstance() {
      return defaultInstance;
    }

    public MasterKeyProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MasterKeyProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              keyId_ = input.readInt32();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              bytes_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_MasterKeyProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_MasterKeyProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder.class);
    }

    public static com.google.protobuf.Parser<MasterKeyProto> PARSER =
        new com.google.protobuf.AbstractParser<MasterKeyProto>() {
      public MasterKeyProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MasterKeyProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MasterKeyProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 key_id = 1;
    public static final int KEY_ID_FIELD_NUMBER = 1;
    private int keyId_;
    /**
     * <code>optional int32 key_id = 1;</code>
     */
    public boolean hasKeyId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 key_id = 1;</code>
     */
    public int getKeyId() {
      return keyId_;
    }

    // optional bytes bytes = 2;
    public static final int BYTES_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString bytes_;
    /**
     * <code>optional bytes bytes = 2;</code>
     */
    public boolean hasBytes() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes bytes = 2;</code>
     */
    public com.google.protobuf.ByteString getBytes() {
      return bytes_;
    }

    private void initFields() {
      keyId_ = 0;
      bytes_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, keyId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, bytes_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, keyId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, bytes_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto) obj;

      boolean result = true;
      result = result && (hasKeyId() == other.hasKeyId());
      if (hasKeyId()) {
        result = result && (getKeyId()
            == other.getKeyId());
      }
      result = result && (hasBytes() == other.hasBytes());
      if (hasBytes()) {
        result = result && getBytes()
            .equals(other.getBytes());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKeyId()) {
        hash = (37 * hash) + KEY_ID_FIELD_NUMBER;
        hash = (53 * hash) + getKeyId();
      }
      if (hasBytes()) {
        hash = (37 * hash) + BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getBytes().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.MasterKeyProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_MasterKeyProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_MasterKeyProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        keyId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        bytes_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_MasterKeyProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.keyId_ = keyId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.bytes_ = bytes_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) return this;
        if (other.hasKeyId()) {
          setKeyId(other.getKeyId());
        }
        if (other.hasBytes()) {
          setBytes(other.getBytes());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 key_id = 1;
      private int keyId_ ;
      /**
       * <code>optional int32 key_id = 1;</code>
       */
      public boolean hasKeyId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 key_id = 1;</code>
       */
      public int getKeyId() {
        return keyId_;
      }
      /**
       * <code>optional int32 key_id = 1;</code>
       */
      public Builder setKeyId(int value) {
        bitField0_ |= 0x00000001;
        keyId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 key_id = 1;</code>
       */
      public Builder clearKeyId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        keyId_ = 0;
        onChanged();
        return this;
      }

      // optional bytes bytes = 2;
      private com.google.protobuf.ByteString bytes_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes bytes = 2;</code>
       */
      public boolean hasBytes() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes bytes = 2;</code>
       */
      public com.google.protobuf.ByteString getBytes() {
        return bytes_;
      }
      /**
       * <code>optional bytes bytes = 2;</code>
       */
      public Builder setBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        bytes_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes bytes = 2;</code>
       */
      public Builder clearBytes() {
        bitField0_ = (bitField0_ & ~0x00000002);
        bytes_ = getDefaultInstance().getBytes();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.MasterKeyProto)
    }

    static {
      defaultInstance = new MasterKeyProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.MasterKeyProto)
  }

  public interface NodeHealthStatusProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bool is_node_healthy = 1;
    /**
     * <code>optional bool is_node_healthy = 1;</code>
     */
    boolean hasIsNodeHealthy();
    /**
     * <code>optional bool is_node_healthy = 1;</code>
     */
    boolean getIsNodeHealthy();

    // optional string health_report = 2;
    /**
     * <code>optional string health_report = 2;</code>
     */
    boolean hasHealthReport();
    /**
     * <code>optional string health_report = 2;</code>
     */
    java.lang.String getHealthReport();
    /**
     * <code>optional string health_report = 2;</code>
     */
    com.google.protobuf.ByteString
        getHealthReportBytes();

    // optional int64 last_health_report_time = 3;
    /**
     * <code>optional int64 last_health_report_time = 3;</code>
     */
    boolean hasLastHealthReportTime();
    /**
     * <code>optional int64 last_health_report_time = 3;</code>
     */
    long getLastHealthReportTime();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeHealthStatusProto}
   */
  public static final class NodeHealthStatusProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeHealthStatusProtoOrBuilder {
    // Use NodeHealthStatusProto.newBuilder() to construct.
    private NodeHealthStatusProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeHealthStatusProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeHealthStatusProto defaultInstance;
    public static NodeHealthStatusProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeHealthStatusProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeHealthStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              isNodeHealthy_ = input.readBool();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              healthReport_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              lastHealthReportTime_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeHealthStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeHealthStatusProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeHealthStatusProto>() {
      public NodeHealthStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeHealthStatusProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeHealthStatusProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bool is_node_healthy = 1;
    public static final int IS_NODE_HEALTHY_FIELD_NUMBER = 1;
    private boolean isNodeHealthy_;
    /**
     * <code>optional bool is_node_healthy = 1;</code>
     */
    public boolean hasIsNodeHealthy() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool is_node_healthy = 1;</code>
     */
    public boolean getIsNodeHealthy() {
      return isNodeHealthy_;
    }

    // optional string health_report = 2;
    public static final int HEALTH_REPORT_FIELD_NUMBER = 2;
    private java.lang.Object healthReport_;
    /**
     * <code>optional string health_report = 2;</code>
     */
    public boolean hasHealthReport() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string health_report = 2;</code>
     */
    public java.lang.String getHealthReport() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          healthReport_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string health_report = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHealthReportBytes() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        healthReport_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 last_health_report_time = 3;
    public static final int LAST_HEALTH_REPORT_TIME_FIELD_NUMBER = 3;
    private long lastHealthReportTime_;
    /**
     * <code>optional int64 last_health_report_time = 3;</code>
     */
    public boolean hasLastHealthReportTime() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 last_health_report_time = 3;</code>
     */
    public long getLastHealthReportTime() {
      return lastHealthReportTime_;
    }

    private void initFields() {
      isNodeHealthy_ = false;
      healthReport_ = "";
      lastHealthReportTime_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, isNodeHealthy_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, lastHealthReportTime_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isNodeHealthy_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, lastHealthReportTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto) obj;

      boolean result = true;
      result = result && (hasIsNodeHealthy() == other.hasIsNodeHealthy());
      if (hasIsNodeHealthy()) {
        result = result && (getIsNodeHealthy()
            == other.getIsNodeHealthy());
      }
      result = result && (hasHealthReport() == other.hasHealthReport());
      if (hasHealthReport()) {
        result = result && getHealthReport()
            .equals(other.getHealthReport());
      }
      result = result && (hasLastHealthReportTime() == other.hasLastHealthReportTime());
      if (hasLastHealthReportTime()) {
        result = result && (getLastHealthReportTime()
            == other.getLastHealthReportTime());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasIsNodeHealthy()) {
        hash = (37 * hash) + IS_NODE_HEALTHY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getIsNodeHealthy());
      }
      if (hasHealthReport()) {
        hash = (37 * hash) + HEALTH_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getHealthReport().hashCode();
      }
      if (hasLastHealthReportTime()) {
        hash = (37 * hash) + LAST_HEALTH_REPORT_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLastHealthReportTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeHealthStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeHealthStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        isNodeHealthy_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        healthReport_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        lastHealthReportTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.isNodeHealthy_ = isNodeHealthy_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.healthReport_ = healthReport_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.lastHealthReportTime_ = lastHealthReportTime_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto.getDefaultInstance()) return this;
        if (other.hasIsNodeHealthy()) {
          setIsNodeHealthy(other.getIsNodeHealthy());
        }
        if (other.hasHealthReport()) {
          bitField0_ |= 0x00000002;
          healthReport_ = other.healthReport_;
          onChanged();
        }
        if (other.hasLastHealthReportTime()) {
          setLastHealthReportTime(other.getLastHealthReportTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeHealthStatusProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bool is_node_healthy = 1;
      private boolean isNodeHealthy_ ;
      /**
       * <code>optional bool is_node_healthy = 1;</code>
       */
      public boolean hasIsNodeHealthy() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool is_node_healthy = 1;</code>
       */
      public boolean getIsNodeHealthy() {
        return isNodeHealthy_;
      }
      /**
       * <code>optional bool is_node_healthy = 1;</code>
       */
      public Builder setIsNodeHealthy(boolean value) {
        bitField0_ |= 0x00000001;
        isNodeHealthy_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool is_node_healthy = 1;</code>
       */
      public Builder clearIsNodeHealthy() {
        bitField0_ = (bitField0_ & ~0x00000001);
        isNodeHealthy_ = false;
        onChanged();
        return this;
      }

      // optional string health_report = 2;
      private java.lang.Object healthReport_ = "";
      /**
       * <code>optional string health_report = 2;</code>
       */
      public boolean hasHealthReport() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string health_report = 2;</code>
       */
      public java.lang.String getHealthReport() {
        java.lang.Object ref = healthReport_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          healthReport_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string health_report = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHealthReportBytes() {
        java.lang.Object ref = healthReport_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          healthReport_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string health_report = 2;</code>
       */
      public Builder setHealthReport(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        healthReport_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 2;</code>
       */
      public Builder clearHealthReport() {
        bitField0_ = (bitField0_ & ~0x00000002);
        healthReport_ = getDefaultInstance().getHealthReport();
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 2;</code>
       */
      public Builder setHealthReportBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        healthReport_ = value;
        onChanged();
        return this;
      }

      // optional int64 last_health_report_time = 3;
      private long lastHealthReportTime_ ;
      /**
       * <code>optional int64 last_health_report_time = 3;</code>
       */
      public boolean hasLastHealthReportTime() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 last_health_report_time = 3;</code>
       */
      public long getLastHealthReportTime() {
        return lastHealthReportTime_;
      }
      /**
       * <code>optional int64 last_health_report_time = 3;</code>
       */
      public Builder setLastHealthReportTime(long value) {
        bitField0_ |= 0x00000004;
        lastHealthReportTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 last_health_report_time = 3;</code>
       */
      public Builder clearLastHealthReportTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        lastHealthReportTime_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeHealthStatusProto)
    }

    static {
      defaultInstance = new NodeHealthStatusProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeHealthStatusProto)
  }

  public interface VersionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 major_version = 1;
    /**
     * <code>optional int32 major_version = 1;</code>
     */
    boolean hasMajorVersion();
    /**
     * <code>optional int32 major_version = 1;</code>
     */
    int getMajorVersion();

    // optional int32 minor_version = 2;
    /**
     * <code>optional int32 minor_version = 2;</code>
     */
    boolean hasMinorVersion();
    /**
     * <code>optional int32 minor_version = 2;</code>
     */
    int getMinorVersion();
  }
  /**
   * Protobuf type {@code hadoop.yarn.VersionProto}
   */
  public static final class VersionProto extends
      com.google.protobuf.GeneratedMessage
      implements VersionProtoOrBuilder {
    // Use VersionProto.newBuilder() to construct.
    private VersionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private VersionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final VersionProto defaultInstance;
    public static VersionProto getDefaultInstance() {
      return defaultInstance;
    }

    public VersionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private VersionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              majorVersion_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              minorVersion_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_VersionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_VersionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<VersionProto> PARSER =
        new com.google.protobuf.AbstractParser<VersionProto>() {
      public VersionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new VersionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<VersionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 major_version = 1;
    public static final int MAJOR_VERSION_FIELD_NUMBER = 1;
    private int majorVersion_;
    /**
     * <code>optional int32 major_version = 1;</code>
     */
    public boolean hasMajorVersion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 major_version = 1;</code>
     */
    public int getMajorVersion() {
      return majorVersion_;
    }

    // optional int32 minor_version = 2;
    public static final int MINOR_VERSION_FIELD_NUMBER = 2;
    private int minorVersion_;
    /**
     * <code>optional int32 minor_version = 2;</code>
     */
    public boolean hasMinorVersion() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 minor_version = 2;</code>
     */
    public int getMinorVersion() {
      return minorVersion_;
    }

    private void initFields() {
      majorVersion_ = 0;
      minorVersion_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, majorVersion_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, minorVersion_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, majorVersion_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, minorVersion_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto) obj;

      boolean result = true;
      result = result && (hasMajorVersion() == other.hasMajorVersion());
      if (hasMajorVersion()) {
        result = result && (getMajorVersion()
            == other.getMajorVersion());
      }
      result = result && (hasMinorVersion() == other.hasMinorVersion());
      if (hasMinorVersion()) {
        result = result && (getMinorVersion()
            == other.getMinorVersion());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMajorVersion()) {
        hash = (37 * hash) + MAJOR_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getMajorVersion();
      }
      if (hasMinorVersion()) {
        hash = (37 * hash) + MINOR_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getMinorVersion();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.VersionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_VersionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_VersionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        majorVersion_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        minorVersion_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.internal_static_hadoop_yarn_VersionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.majorVersion_ = majorVersion_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.minorVersion_ = minorVersion_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto.getDefaultInstance()) return this;
        if (other.hasMajorVersion()) {
          setMajorVersion(other.getMajorVersion());
        }
        if (other.hasMinorVersion()) {
          setMinorVersion(other.getMinorVersion());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonProtos.VersionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 major_version = 1;
      private int majorVersion_ ;
      /**
       * <code>optional int32 major_version = 1;</code>
       */
      public boolean hasMajorVersion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 major_version = 1;</code>
       */
      public int getMajorVersion() {
        return majorVersion_;
      }
      /**
       * <code>optional int32 major_version = 1;</code>
       */
      public Builder setMajorVersion(int value) {
        bitField0_ |= 0x00000001;
        majorVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 major_version = 1;</code>
       */
      public Builder clearMajorVersion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        majorVersion_ = 0;
        onChanged();
        return this;
      }

      // optional int32 minor_version = 2;
      private int minorVersion_ ;
      /**
       * <code>optional int32 minor_version = 2;</code>
       */
      public boolean hasMinorVersion() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 minor_version = 2;</code>
       */
      public int getMinorVersion() {
        return minorVersion_;
      }
      /**
       * <code>optional int32 minor_version = 2;</code>
       */
      public Builder setMinorVersion(int value) {
        bitField0_ |= 0x00000002;
        minorVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 minor_version = 2;</code>
       */
      public Builder clearMinorVersion() {
        bitField0_ = (bitField0_ & ~0x00000002);
        minorVersion_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.VersionProto)
    }

    static {
      defaultInstance = new VersionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.VersionProto)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeStatusProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeStatusProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_MasterKeyProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_MasterKeyProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeHealthStatusProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_VersionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_VersionProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\037yarn_server_common_protos.proto\022\013hadoo" +
      "p.yarn\032\021yarn_protos.proto\"\323\003\n\017NodeStatus" +
      "Proto\022)\n\007node_id\030\001 \001(\0132\030.hadoop.yarn.Nod" +
      "eIdProto\022\023\n\013response_id\030\002 \001(\005\022=\n\022contain" +
      "ersStatuses\030\003 \003(\0132!.hadoop.yarn.Containe" +
      "rStatusProto\022<\n\020nodeHealthStatus\030\004 \001(\0132\"" +
      ".hadoop.yarn.NodeHealthStatusProto\022@\n\027ke" +
      "ep_alive_applications\030\005 \003(\0132\037.hadoop.yar" +
      "n.ApplicationIdProto\022E\n\026containers_utili" +
      "zation\030\006 \001(\0132%.hadoop.yarn.ResourceUtili",
      "zationProto\022?\n\020node_utilization\030\007 \001(\0132%." +
      "hadoop.yarn.ResourceUtilizationProto\0229\n\024" +
      "increased_containers\030\010 \003(\0132\033.hadoop.yarn" +
      ".ContainerProto\"/\n\016MasterKeyProto\022\016\n\006key" +
      "_id\030\001 \001(\005\022\r\n\005bytes\030\002 \001(\014\"h\n\025NodeHealthSt" +
      "atusProto\022\027\n\017is_node_healthy\030\001 \001(\010\022\025\n\rhe" +
      "alth_report\030\002 \001(\t\022\037\n\027last_health_report_" +
      "time\030\003 \001(\003\"<\n\014VersionProto\022\025\n\rmajor_vers" +
      "ion\030\001 \001(\005\022\025\n\rminor_version\030\002 \001(\005*7\n\017Node" +
      "ActionProto\022\n\n\006NORMAL\020\000\022\n\n\006RESYNC\020\001\022\014\n\010S",
      "HUTDOWN\020\002B<\n\034org.apache.hadoop.yarn.prot" +
      "oB\026YarnServerCommonProtos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hadoop_yarn_NodeStatusProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hadoop_yarn_NodeStatusProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeStatusProto_descriptor,
              new java.lang.String[] { "NodeId", "ResponseId", "ContainersStatuses", "NodeHealthStatus", "KeepAliveApplications", "ContainersUtilization", "NodeUtilization", "IncreasedContainers", });
          internal_static_hadoop_yarn_MasterKeyProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hadoop_yarn_MasterKeyProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_MasterKeyProto_descriptor,
              new java.lang.String[] { "KeyId", "Bytes", });
          internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hadoop_yarn_NodeHealthStatusProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeHealthStatusProto_descriptor,
              new java.lang.String[] { "IsNodeHealthy", "HealthReport", "LastHealthReportTime", });
          internal_static_hadoop_yarn_VersionProto_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hadoop_yarn_VersionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_VersionProto_descriptor,
              new java.lang.String[] { "MajorVersion", "MinorVersion", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
